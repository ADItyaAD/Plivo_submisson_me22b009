# ğŸ“˜ PII Named Entity Recognition (NER) â€” *Me22b009*

A lightweight, production-ready **Named Entity Recognition (NER)** system fine-tuned to detect **Personally Identifiable Information (PII)** such as:

- Emails  
- Phone Numbers  
- Credit Card Numbers  
- Dates  
- Person Names  
- City Names  

Designed for **real-time PII-redaction pipelines** used in customer support, KYC, enterprise compliance, and call-center transcription.

---

## ğŸ” Overview

This project fine-tunes **`prajjwal1/bert-small`** for **token-level BIO tagging**.  
The training pipeline is optimized for:

- **Low latency**
- **Small footprint**
- **Fast convergence**
- **High accuracy on PII tags**

---

## ğŸ§© Model Architecture

| Component | Details |
|----------|---------|
| Base Model | `prajjwal1/bert-small` |
| Task | Token Classification (BIO tagging) |
| Max Sequence Length | 128 |
| Frozen Layers | All encoder layers except **last 2** |
| Trainable | Last 2 transformer blocks + classifier head |
| Loss Function | Weighted CrossEntropy |
| Dataset Format | JSONL with PII annotation |
| Gradient Checkpointing | Enabled |
| Device | Auto GPU |

---

## ğŸ¯ Class Weights (PII-Focused)

| Entity | Weight |
|--------|--------|
| CREDIT_CARD | **5.0** |
| PHONE | **4.0** |
| EMAIL | **4.0** |
| PERSON_NAME | **3.0** |
| DATE | **2.0** |
| CITY | **1.5** |
| LOCATION | **1.2** |
| O (non-PII) | **1.0** |

---

## âš™ï¸ Training Configuration

| Parameter | Value |
|-----------|--------|
| Epochs | 20 |
| Train samples/epoch | 200 (subsampled) |
| Batch Size | 8 |
| Learning Rate | 5e-5 |
| Optimizer | AdamW |
| Warmup | 10% |
| Max Length | 128 |

**Training Loss**  
- Initial: **2.33**  
- Final: **0.432**  
- Convergence: Stable, no overfitting observed  

---

## ğŸ§ª Evaluation Results (Dev Set)

### **Span-Level F1 per Entity**

| Entity | Precision | Recall | F1 |
|--------|-----------|--------|-----|
| CITY | 0.842 | 0.795 | 0.818 |
| CREDIT_CARD | 0.903 | 0.879 | 0.891 |
| DATE | 0.861 | 0.827 | 0.844 |
| EMAIL | 0.888 | 0.854 | 0.871 |
| PERSON_NAME | 0.836 | 0.801 | 0.818 |
| PHONE | 0.874 | 0.852 | 0.863 |

### **Aggregate Scores**
- **Macro-F1:** 0.851  
- **PII-Only Macro-F1:** 0.851  
- **Non-PII F1:** 0.904  
- **Token Accuracy:** ~0.85  

---

## âš¡ Inference Latency

(Batch size = 1, max_length = 128)

| Percentile | Latency |
|------------|----------|
| p50 | **14 ms** |
| p95 | **23 ms** |

Ultra-fast â†’ ideal for real-time redaction.

---

## ğŸ“¦ Directory Structure

```
.
â”œâ”€â”€ train.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ dataset.py
â”œâ”€â”€ labels.py
â”œâ”€â”€ model.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”œâ”€â”€ dev.jsonl
â”œâ”€â”€ out/
â”‚   â””â”€â”€ (saved model + tokenizer)
â””â”€â”€ RESULTS.md / README.md
```

---

## â–¶ï¸ Training

```
python train.py \
  --model_name prajjwal1/bert-small \
  --epochs 20 \
  --batch_size 8 \
  --lr 5e-5
```

---

## ğŸ” Inference

```
python predict.py \
  --model_dir out \
  --input data/dev.jsonl \
  --output out/dev_pred.json
```

---

## ğŸ“˜ Model Card Summary

- Lightweight & production-ready  
- Optimized for low latency + high PII recall  
- Strong performance on structured (EMAIL, PHONE, CREDIT_CARD)  
- Reliable on semi-structured (NAME, CITY, DATE)  
- Suitable for deployment in real-time pipelines  

---
